import{_ as i,c as a,o as e,ag as l}from"./chunks/framework.CldZrGrL.js";const k=JSON.parse('{"title":"MCP 服务器指南","description":"","frontmatter":{},"headers":[],"relativePath":"guide/mcp-server.md","filePath":"guide/mcp-server.md"}'),n={name:"guide/mcp-server.md"};function t(o,s,p,d,h,c){return e(),a("div",null,[...s[0]||(s[0]=[l(`<h1 id="mcp-服务器指南" tabindex="-1">MCP 服务器指南 <a class="header-anchor" href="#mcp-服务器指南" aria-label="Permalink to &quot;MCP 服务器指南&quot;">​</a></h1><p>Milvus Tools 附带一个 Model Context Protocol (MCP) 服务器，方便 Claude、Gemini 等 AI 应用通过标准协议读取 Milvus 数据。服务器运行 <code>milvus-mcp-server.js</code>，默认使用 Ollama 做 local embedding。</p><h2 id="运行前准备" tabindex="-1">运行前准备 <a class="header-anchor" href="#运行前准备" aria-label="Permalink to &quot;运行前准备&quot;">​</a></h2><ol><li>确保 Milvus 通过 Docker Compose 启动，并且 <code>config.json.milvus.address</code> 指向正确主机。</li><li>启动 Ollama（或其他支撑 Embedding 的服务）并拉取对应模型。</li><li>安装依赖：<code>pnpm install</code>（如果还没执行过）。</li></ol><h2 id="启动服务器" tabindex="-1">启动服务器 <a class="header-anchor" href="#启动服务器" aria-label="Permalink to &quot;启动服务器&quot;">​</a></h2><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MILVUS_HOST</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">127.0.0.1</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> \\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MILVUS_PORT=19530 </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">OLLAMA_MODEL=nomic-embed-text </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">OLLAMA_BASE_URL=http://127.0.0.1:11434 </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">EMBEDDING_DIM=768 </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">node </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">scripts/mcp/milvus-mcp-server.js</span></span></code></pre></div><ul><li><code>EMBEDDING_DIM</code> 必须与你当前使用的 Schema 向量维度一致。</li><li><code>OLLAMA_MODEL</code> 可以是你已拉取的模型，如 <code>nomic-embed-text</code>。</li><li>支持通过 <code>TOPK</code> 指定返回的 Top-K 大小。</li></ul><p>启动后，MCP 服务器会监听标准输入/输出协议，可以被 Claude 等模型作为外部工具直接调用。你也可以在本地通过 <code>curl</code> 或 Postman 验证：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">curl</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --request</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> POST</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --header</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;content-type: application/json&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --data</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;{&quot;name&quot;:&quot;list_tools&quot;}&#39;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  http://localhost:8000/</span></span></code></pre></div><h2 id="常见问题" tabindex="-1">常见问题 <a class="header-anchor" href="#常见问题" aria-label="Permalink to &quot;常见问题&quot;">​</a></h2><ul><li><strong>无法连接 Milvus？</strong> 确认 Docker Compose 中 Milvus 服务已经 <code>docker compose ps</code> 显示为 <code>running</code>，且 <code>config.json.milvus.address</code> 与 <code>MILVUS_HOST</code>/<code>MILVUS_PORT</code> 一致。</li><li><strong>Embedding 请求失败？</strong> 检查 Ollama HTTP 接口（默认 <code>11434</code>）是否可达，可以用 <code>curl http://127.0.0.1:11434/api/tags</code>。</li><li><strong>想切换到 OpenAI？</strong> 设置 <code>provider</code> 为 <code>openai</code>，并通过 <code>OPENAI_API_KEY</code> 环境变量提供密钥。MCP 服务器当前只演示 Ollama，因此你需要在代码中拓展 Embedding 逻辑。</li></ul>`,11)])])}const g=i(n,[["render",t]]);export{k as __pageData,g as default};

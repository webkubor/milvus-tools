import inquirer from 'inquirer';
import fs from 'node:fs/promises';
import path from 'node:path';
import os from 'node:os';

const CONFIG_FILE = path.join(process.cwd(), 'config.json');

async function getOllamaModels() {
  try {
    const response = await fetch('http://127.0.0.1:11434/api/tags');
    if (!response.ok) return [];
    const data = await response.json();
    return data.models?.map(m => m.name) || [];
  } catch (e) {
    return [];
  }
}

async function setup() {
  console.log('ğŸš€ æ¬¢è¿ä½¿ç”¨ Milvus Tools äº¤äº’å¼é…ç½®\n');

  // è¯»å–ç°æœ‰é…ç½®
  let existingConfig = {};
  try {
    const raw = await fs.readFile(CONFIG_FILE, 'utf-8');
    existingConfig = JSON.parse(raw);
  } catch (e) {}

  // é¢„è·å– Ollama æ¨¡å‹åˆ—è¡¨
  const installedModels = await getOllamaModels();
  const hasModels = installedModels.length > 0;

  const answers = await inquirer.prompt([
    {
      type: 'input',
      name: 'milvusAddress',
      message: 'Milvus è¿æ¥åœ°å€:',
      default: existingConfig.milvus?.address || '127.0.0.1:19530'
    },
    {
      type: 'input',
      name: 'collectionName',
      message: 'Collection åç§°:',
      default: existingConfig.milvus?.collection || 'ai_common_chunks'
    },
    {
      type: 'list',
      name: 'embedProvider',
      message: 'é€‰æ‹© Embedding æä¾›æ–¹:',
      choices: ['ollama', 'mock'],
      default: existingConfig.embedding?.provider || 'ollama'
    },
    // åœºæ™¯ A: å‘ç°äº†æ¨¡å‹ï¼Œæä¾›åˆ—è¡¨é€‰æ‹©
    {
      type: 'list',
      name: 'ollamaModelSelected',
      message: 'é€‰æ‹©å·²å®‰è£…çš„ Ollama æ¨¡å‹:',
      choices: [...installedModels, new inquirer.Separator(), 'æ‰‹åŠ¨è¾“å…¥å…¶ä»–æ¨¡å‹'],
      when: (a) => a.embedProvider === 'ollama' && hasModels,
      default: existingConfig.embedding?.model
    },
    // åœºæ™¯ B: æ²¡å‘ç°æ¨¡å‹ï¼Œæˆ–ç”¨æˆ·é€‰æ‹©æ‰‹åŠ¨è¾“å…¥
    {
      type: 'input',
      name: 'ollamaModelManual',
      message: 'è¯·è¾“å…¥ Ollama æ¨¡å‹åç§°:',
      default: existingConfig.embedding?.model || 'nomic-embed-text',
      when: (a) => a.embedProvider === 'ollama' && (!hasModels || a.ollamaModelSelected === 'æ‰‹åŠ¨è¾“å…¥å…¶ä»–æ¨¡å‹')
    },
    {
      type: 'number',
      name: 'embeddingDim',
      message: 'Embedding ç»´åº¦ (nomic-embed-text: 768, bge-m3: 1024):',
      default: (a) => {
        const model = a.ollamaModelSelected || a.ollamaModelManual || '';
        if (model.includes('nomic')) return 768;
        if (model.includes('bge-m3')) return 1024;
        return existingConfig.embedding?.dim || 768;
      }
    },
    {
      type: 'input',
      name: 'aiCommonRoot',
      message: 'çŸ¥è¯†åº“æ ¹ç›®å½• (AI_Common):',
      default: existingConfig.dataSource?.root || path.join(os.homedir(), 'Documents', 'AI_Common'),
      filter: (val) => val.replace(/^~/, os.homedir())
    }
  ]);

  const finalModel = answers.ollamaModelSelected === 'æ‰‹åŠ¨è¾“å…¥å…¶ä»–æ¨¡å‹' 
    ? answers.ollamaModelManual 
    : (answers.ollamaModelSelected || answers.ollamaModelManual);

  const config = {
    milvus: {
      address: answers.milvusAddress,
      collection: answers.collectionName
    },
    embedding: {
      provider: answers.embedProvider,
      model: finalModel,
      dim: answers.embeddingDim,
      baseUrl: 'http://127.0.0.1:11434'
    },
    dataSource: {
      root: answers.aiCommonRoot
    }
  };

  await fs.writeFile(CONFIG_FILE, JSON.stringify(config, null, 2), 'utf-8');

  console.log('\nâœ… é…ç½®å·²ä¿å­˜åˆ° config.json');
  console.log('--------------------------------------------------');
  console.log(JSON.stringify(config, null, 2));
  console.log('--------------------------------------------------');
  console.log('ğŸ’¡ å»ºè®®è¿è¡Œ pnpm run milvus:doctor éªŒè¯æ¨¡å‹å’Œç«¯å£çŠ¶æ€ã€‚');
}

setup().catch(console.error);